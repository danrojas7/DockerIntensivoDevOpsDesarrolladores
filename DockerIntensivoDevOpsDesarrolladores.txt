

Docker Intensivo para DevOps y Desarrolladores

- Introducción a las tecnologías de virtualización
- Arquitectura Cliente-Servidor de Docker
- Instalación de Docker en nuestra máquina
- Conceptos importantes de Docker
- Correr nuestro primer container Hello World! en Docker
- Comandos más útiles para trabajar con Docker
- Capas de imagen
- Docker commit - crear imagenes
- Docker file
- Instrucciones del dockerfile
- Push de imagenes

- Dockerizar una aplicación sencilla
- Servicio de búsqueda con redis
- Enlazar contenedores
- Vinculación de contenedores de manera interna
- Automatizar el flujo de trabajo con docker-compose

- Pruebas unitarias para probar la aplicación dockerizada
- Flujo de trabajo con docker, github y CircleCI para crear una pipeline de integración continua

- Ejecutar docker en producción
- Desplegar nuestra aplicación dockerizada servidor de producción con Digital Ocean
- Docker swarm, para escalar los flujos de trabajo


Código fuente utilizad en GitHub
- https://github.com/jleetutorial/dockerapp

Grupo de Facebook de Learning DevOps
https://www.facebook.com/groups/1911219079195863


Vitualización basada en contenedores
- Previrtualización
    Grandes racks de servidores, cada servidor un sistema operativo y solamente pueden ejecutar un servicio
    Alto costo ya que se deben adquirir servidores
    Subutilizando recursos de RAM y CPU
    Despliegue lento, proceso de compra y configuración puede tomar mucho tiempo para grandes empresas
    Difíciles de migrar aplicaciones

Virtualización basada en Hypervisor
- Servidor físico
- Sistema Operativo
- Hypervisor
- Instalación de varios sistemas operativos
- Instalación de varias aplicaciones sobre los sistemas operativos
- VMWare y VirtualBox
- AWS - Microsoft Azure

Ventajas
- Más Rentable
- Propios recursos
- Pago por potencia de computo y almacenamiento
- Facil de escalar
- Reducción del tiempo de semanas en minutos

Limitaciones
- Duplicación del recurso del kernel, varios sistemas operativos para atender el servicio de aplicaciones
- Problemas con la portabilidad de la aplicación

Virtualización basada en contenedores

- Servidor físico -máquina física o máquina virtualización
- Sistema operativo
- Motor de contenedores
- Instancia de invitado o contenedor
- Aplicación con sus respectivas librerías
- Replicación de kernels, comparten un único kernel, suministra binarios y tiempos de ejecución
- Virtualización a nivel del sistema operativo

Aislamiento
- Cómo ejecutar aplicaciones en distintos entornos de ejecución de Java, aislados por contenedores
- Aislamiento de tiempo de ejecución

Beneficios
- Más rentable, no crea un SO completo, solamente los componentes necesarios se empaquetan en el contenedor con la aplicación
- Menor consumo de RAM y CPU
- Velocidad de implementación aún más rápida
- Gran portabilidad, ya que cuentan con todo lo necesario para su ejecución dentro del contenedor, se puede ejcutar en todas la máquinas sin problemas de portabilidad


Arquitectura cliente-servidor de docker
- Docker utiliza la arquitectura cliente-sevidor, con el daemon de docker como servidor, el usuario no interactúa directamente con el daemon de docker, sino a través del cliente docker. El cliente de docker es la interfaz principal de comunicación entre el usuario y el servidor
- Cliente con línea de comandos - Kitematic, cliente gráfico
- Daemon es un proceso persistente que hace el trabajo pesado como construir, ejecutar y distribuir los contenedores docker, a menudo conocidos como docker dameon, docker engine, ó docker server
- En una instalación típica de linux, el cliente docker, el daemon docker y el contenedor se ejecutan en el mismo host, también se puede conectar el cliente local de docker, con un servidor remoto de docker.
- No se puede ejecutar docker de forma nativa en mac, Windows, y en general en platformas que no sean Linux, porque este utiliza funciones específicas del kernel de Linux

Instalación de docker en varios sistemas operativos

$ docker info   # mostrará la información de todo el sistema sobre docker


Instalar docker toolbox

Conceptos importantes que hay que entender acerca de la tecnología de docker
- Las imágenes son plantillas de lectura utilizadas para crear contenedores
- Las imágenes se crean mediante el comando build de docker, por nosotros y otros usuarios de docker
- Las imágenes son compuestas de capas de otras imágenes
- Las imágenes solo se almacenan en un registro de docker

Contenedores
- Haciendo una analogía con la POO, si una imagen es una clase, entonces un contenedor es una instancia de una clase, un objeto de tiempo de ejecución
- Los contenedores son livianos y portátiles de un entorno en el cual se pueden ejecutar aplicaciones
- Los contenedores son creados de imágenes. Dentro de un contenedor, tenemos todos los binarios y dependencias que necesitamos para ejecutar la aplicación

Registros y repositorios
- Un registro es donde están almacenadas nuestras imágenes
- Puedes alojar tu propio registro, o puedes usar el registro público de Docker el cual es llamado DockerHub
- Dentro de un registro, las imágenes se almacenan en repositorios
- El repositorio de Docker es una colección de diferentes imágenes de docker con el mismo nombre, que tienen etiquetas, cada etiqueta generalmente representa una versión diferente de la imagen

Por qué se utilizan imágenes oficiales?
- Documentación clara
- Docker.inc, tiene un equipo dedicado a la revisión del contenido de las imágenes
- Actualizaciones de seguridad de manera oportuna
- Repositorios certificados por docker

$ docker images                                 # comando para mostrar las imágenes en el registro local de docker
$ docker run busybox:1.24 echo "hello world"    # crea un contenedor a partir de una imagen
$ docker run --rm --name helloworld -d busybox:1.24     # crea un contenedor, que cuando termine la ejecución, se borra, que se llama helloworld, y basado en la imagen busybox:1.24
$ docker run -ti busybox:1.4                    # crea un nuevo contenedor con ingreso a terminal dentro del contenedor


$ docker run -d busybox:1.24 sleep 1000         # crea un contenedor en segundo plano o en background con el modificador -d. Contenedores empezaron en modo detached y salen cuando el proceso raíz usado para ejecutar el contenedor sale

$ docker ps                                     # listar los contenedores que se encuentran actualmente en ejecución
$ docker ps -acerca                             # listar todos los contenedores, incluso los que ya no están en ejecución
$ docker run --rm busybox:1.24 sleep 1          # crea un contenedor con el comando sleep de un segundo, para que se mantenga en ejecución por un segundo, y a continuación cuando se detiene, se elimina ya que se le envió el modificador --rm
$ docker run --name hello_world busybox:1.24    # especifica el nombre hello_world, mediante el modificador --name
$ docker inspect                                # mostrar la información de bajo nivel sobre un contenedor o imagen


Continuación comandos docker
Docker port mapping
Docker logs

$ docker run -it --rm -p 8080:8080 tomcat:latest
$ docker logs {id_contenedor}

Para aprender más sobre el uso de Docker Logging, entra al siguiente enlace:

https://www.level-up.one/deep-dive-into-docker-logging/

Capas de imágenes en docker

Una imagen de docker se compone de una lista de capas de solo lectura, que representan un conjunto de cambios en el sistema de archivos del contenedor, las capas de imágenes se agrupan una encima de otra y crean una última capa en modo escritura para los contenedores. Cada imagen consiste de múltiples capas, y cada capa es solo otra imagen, las imágenes padres son de solo lectura, y encuentra debajo de la capa editable. La imagen que se encuentra en la parte interior, se denomina imagen base. Docker realiza todos los cambios en la capa editable. También se puede saber qué conjunto de imágenes conforman una imagen, ejecutando el comando history de docker:

$ docker history busybox:1.24

Cuando se crea un nuevo contenedor, se crea una nueva capa delgada y en modo escritura encima de la pila existente. A esa capa a menudo se le denomina capa de contenedor editable. Todos los cambios realizados en el contenedor en ejecución, como la escritura de archivos nuevos, la modificación de archivos existentes, y la eliminación de archivos, se escribe en esta capa.
La principal diferencia entre un contenedor y una imagen, es la capa superior en modo escritura. Todos los cambios en el contenedor, que agregan datos nuevos o  modifican los existentes, se almacenan en esta capa. Cuando se elimina el contenedor, esta capa también se elimina, la imagen subyacente permanece sin cambios ya que cada contenedor tiene su propia capa editable, y todos los cambios se almacenan en ésta. Esto significa que múltiples contenedores, pueden contener el acceso a la misma imagen subyabcente, y tener su propio estado de datos.

1. Todos los cambios realizados en el contenedor en ejecución serán escritos en la capa editable.
2. Cuando el contenedor es eliminado, la capa editable es también eliminada, pero la imagen subyacente permanece sin cambios.
3. Múltiples contenedores pueden compartir acceso a la misma imagen subyacente.


Construir imágenes docker

1. Hacer commit de los cambios realizados en un contenedor
2. Escribir un Dockerfile

Pasos
1. Lanzar un contenedor desde una imagen base
2. Instala el paquete git en el contenedor
3. Usar docker commit para guardar los cambios realizados en un contenedor

Se crea un nuevo contenedor a partir de la imagen de dockerhub de debian:jessie
$ docker run -it debian:jessie

Si se requiere una nueva versión de la imagen con el cliente git instalado, se abre una terminal del contenedor, y a continuación se instala con las siguientes instrucciones:
$ apt-get update && apt-get install -y git

Ahora para guardar la capa de contenedor de docker como una nueva imagen, se utiliza el comando docker commit:

DOcker commit
- El comando docker commit guardará los cambios que hemos realizado en el sistema de archivos del contenedor docker a una nueva imagen

$ docker commit container_id repository_name:tag

Al realizar commit, se guarda en el reposotorio local de docker
$ docker commit b54675f35b9b danrojas7/debian:1.0

Ahora se puede crear un nuevo contenedor basado en la nueva imagen de docker que se acabó de construir:

docker run -it danrojas7/debian:1.0

para subir la imagen, se utiliza el siguiente comando:

$ docker login                          # se ingresa el usuario y la contraseña por el prompt
$ docker push danrojas7/debian:1.0


Construcción de imágenes docker mediante archivos docker o dockerfiles

Un Dockerfile es un documento de texto que contiene todas las instrucciones que los usuarios proporcionan para construir una imagen

Una instruccion puede ser la instalación un nuevo programa, agregar un código fuente o especificar un comando que se ejecutará posteriormente de inicializado el contenedor

Docker puede construir imágenes automáticamente leyendo las instrucciones desde un Dockerfile
- Cada instrucción creará una nueva capa de imagen para la imagen
- Las instrucciones especifican qué hacer al construir la imagen

Un Dockerfile no debe tener ninguna extensión, para crearlo, se utiliza los siguientes comandos:

$ touch Dockerfile
$ vim Dockerfile

FROM debian:jessie      # FROM: Para indicar la imagen desde donde se está construyendo
RUN apt-get update && apt-get install -y git        # RUN: Se utiliza para indicar los comandos que se van a ejecutar, desde una terminal de comandos linux
RUN apt-get install -y vim

A continuación, para construir la imagen con el Dockerfile recién creado, se ejecuta el siguiente comando:

$ docker build -t danrojas/debian .

De igual manera, el comando docker build, requiere una ruta, que es una ruta a el contexto de compilación de docker

Contexto de compilación de Docker
- El comando docker build toma la ruta al contexto de compilación como un argumento. La ruta especifica donde encontrar los archivos para el contexto de la compilación en el docker daemon. Por ejemplo si quisiéramos copiar un código fuente del disco local al contenedor, estos archivos deberían encontrarse en la ruta del contexto de compilación. Es de recordar que el docker daemon puede ejecutarse en una máquina remota, y que el Dockerfile no se analizará del lado del cliente. En el proceso de compilación el cliente docker primer empaquetará todos los archivos del contexto de compilación en un tarball, luego transfiere el archivo tarball al Docker Daemon.
- Por defecto, docker buscará el archivo Dockerfile en la ruta del contexto de compilación. Si el Dockerfile no se encuentra en la ruta del contexto de compilación, se puede indicarle a Docker que busque el archivo en la ruta del archivo proporcionado por la opción -f

Cuando se inicia el proceso de compilación de la imagen, el proceso de compilación comprende:
- En pimer lugar muestra el contexto de compilación enviado al docker daemon. El cliente de docker está transfiriendo todos los archivos dentro del contexto de compilación que es el directorio actual desde la máquina local al docker daemon.
- Docker sigue las instrucciones del Dockerfile, en el paso 2 ejecuta el paso de instalación de los paquetes con el apt-get, se puede ver la id del contenedor, lo que ocurre es que docker inicia un nuevo contenedor, de la imagen base de debian, y a continuación realiza la instalación a partir de los comandos apt-get especificados, estos contenedores se eliminan automáticamente
- El docker daemon ejecuta cada instrucción dentro de cada contenedor, un contenedor es un proceso editable que escribirá los cambios en el sistema de archivos en una imagen, en el caso particular se instalará un programa. Una vez que docker escrito los cambios en la imagen y la ha guardado, docker eliminará el contenedor. Entonces para cada instrucción, docker creará un nuevo contenedor, ejecuta las instrucciones, agregará una nueva capa a la imágen, y eliminará el contenedor. Básicamente los contenedores son temporales, simplemente se utilizan los contenedores para escribir capas de imágenes, y una vez que se terminan son eliminados. Las imágenes son persistentes y de sólo lectura.
- Una vez que los pasos se hayan completado, los pasos de la compilación se han ejecutado satisfactoriamente.
- Cuando no se especifica una etiqueta, la imagen queda con la etiqueta latest

Dockerfile en detalle
- Cada comando RUN ejecutará el comando en la capa superior editable del contenedor, y luego guardará el contenedor como una nueva imagen.
- La nueva imagen es usada en el siguiente paso en el Dockerfile. Entonces cada instrucción RUN creará una nueva capa de imagen.
- Es recomendado enlazar las instrucciones RUN en el Dockerfile para reducir el número de capas de imágenes que son creadas.


Dockerfile modificado:

FROM debian:jessie
RUN apt-get update && \
    apt-get install -y \
    git \
    vim # Se escribe en un solo comando la actualización y la instalación de paquetes para que se procesen en una sola imagen, resultando en una sola capa en lugar de 3
CMD ["echo", "hello world"]

Ordenar los Argumentos de varias líneas en forma Alfanumérica
- Esto ayudará a evitar la duplicidad de paquetes, esto ayudará a evitar la duplicación de paquetes, y facilitará la actualización de la lista


Instrucción CMD
- La instrucción CMD especifica qué comando quiere ejecutar cuando el contenedor se inicia
- Si no se especifica la instrucción CMD en el Dockerfile, docker usará el comando por defecto definido en la imagen base
- En el caso particular de la imagen debian jessie, el comando predeterminado es bash
- La instrucción CMD no se ejecuta cuando se construye la imagen, solamente se ejecutará cuando el contenedor se inicie
- Es posible ejecutar el comando en cualquiera de los formatos exec que se prefiera o en forma de shell

$ docker run --rm danrojas7/debian:2.0

También se puede sobreescribir el comando enviado como segundo argumento el comando a ejecutar
$ docker run --rm danrojas7/debian:2.0 echo "Hello docker"


Docker cache
- La compilación de los comandos en docker es más rápida que la primera vez, y esto es debido al docker caché
- Cada vez que Docke ejecuta una instrucción crea una nueva capa de imagen
- La siguiente vez, si la instrucciónno cambia, Docker simplemente reutilizará la capa existente

Sin embargo, si docker caché se utiliza demasiado, esto puede ocasionar problemas.
- Por ejemplo se tiene el siguiente Dockerfile:
FROM ubuntu:14.04
RUN apt-get update
RUN apt-get install -y git curl # Se especificará adicional el curl para instalará
- Docker detecta que las 2 primeras instrucciones no variarán, por lo tanto utilizará para ellas el docker caché
- Debido a que la actualización no se ejecuta, es posible que se obtenga una versión desactualizada de los paquetes

La solución es enlazar los comandos apt-get update e install, de modo, que siempre que se actualice la instrucción install, siempre traerá la última versión de los paquetes

FROM ubuntu:14.04
RUN apt-get update && \
    apt-get install -y \
    git \
    curl

También es posible indicarle a docker, que invalide la caché, utlizando el indicador de --no-cache=true

$ docker build --no-cache=true -t danrojas7/debian .

Instrucción COPY
La instrucción COPY copia nuevos archivos o directorios del contexto de compilación y los agrega al sistema de archivos del contenedor

instrucción ADD
La diferencia con COPY, es que ADD permite además descargar un archivo de internet y copiarlo en el contenedor
La instrucción ADD también tiene la capacidad de descomprimir automáticamente los archivos comprimidos
La regla es: usar COPY a menos que se esté seguro que no se necesite ADD


Llevando las imagenes al dockerhub
Llevar la imágenes docker al repositorio público de dockerhub, para que otros desarrolladores las puedan utilizar. De las imágenes construidas de forma manual con un commit, o con un Dockerhub
crear una cuenta en Docker Hub https://hub.docker.com

Muestra las imágenes de docker instaladas en el daemon de docker local
$ docker images

Espeficar etiqueta y tag a una imagen docker
$ docker tag id_contenedor danrojas7/debian:2.0

$ docker login
$ docker login --username=danrojas7
Ingresar usuario y contraseña

Hacer push a la imagen
$ docker push cuenta_docker_hub/imagen:tag
$ docker push danrojas7/debian:2.0

Última etiqueta
- Docker usará la etiqueta predeterminada latest cuando no se proporcione ninguna etiqueta
- Muchos repositorios usan esto para etiquetar la imagen estable más actualizada, sin embargo esto es aún solo una convención y no es algo obligatorio
- Las imágenes que son etiquetadas como latest no serán actualizadas automáticamente cuando se envíe una nueva versión de la imagen al repositorio
- Ignorar la etiqueta latest



Práctica de Docker

Descargar el proyecto de python desde el repositorio de github:
https://github.com/jleetutorial/dockerapp.git

Ejecutar el siguiente comando para iniciar sobre la versión del proyecto a trabajar
$ git checkout branch-v0.1

Dockerfile:

FROM python:3.5
RUN pip install Flask==0.11.1 redis==2.10.5
RUN useradd -ms /bin/bash admin                 # Crea un usuario, con la shell definida por defecto
USER admin                                      # Cambia al usuario creado anteriormente
COPY app /app                                   # Copia el directorio dentro del contenedor
WORKDIR /app                                    # Cambia al directorio de trabajo
CMD ["python", "app.py"]                        # Inicia la aplicación


Hacer build de la imagen:
$ docker build -t jleetutorial/dockerapp:0.1 .

Inicializar un contenedor docker, con la aplicación a partir de la imagen recién construída
$ docker run -d -p 5000:5000 --name python-dockerapp jleetutorial/dockerapp:0.1

Comando en linux y en Mac, para obtener detalles de la máquina virtual, como la dirección IP sobre la cual está en ejecución
$ docker-machine ls

Comando para inciar sesión dentro del contenedor:
$ docker exec -it python-dockerapp bash

Dentro del contenedor, ejecutar el comando siguiente, para comprobar el proceso python con la aplicación en ejecución, y que el contenedor esté en ejecución por el usuario creado en el Dockerfile, y no por el usuario root
$ ps aux


Comando en git para guardar los cambios provisionales, reestableciendo el estado de la rama al estado original, dando la posibilidad de cambiar de rama

$ git stash
.. Se realizan cambios en otras ramas, y se vuelve a la rama original
$ git stash list    # muestra los stash guardados
$ git stash apply   # Se regresa al punto de modificación del repositorio antes de ejecutar git stash

Uso de redis
- Redis es una estructura de datos de memoria integrada, usando como base de datos, caché y message broker
- Replicación incorporada y diferentes niveles de persistencia en disco
- Ampliamente usado en muchos productos críticos en el campo tales como Servicio Timeline de Twitter y Noticias de Facebook


Ejecutar la imagen de redis en un contenedor:
$ docker run -d --name redis redis:3.2.0

Hacer build de la imagen, e iniciar una nueva versión del contenedor:
$ docker build -t jleetutorial/dockerapp:0.3 .
$ docker run -d -p 5000:5000 --name python-dockerapp --link redis jleetutorial/dockerapp:0.3

Iniciar sesión en el contenedor
docker exec -it python-dockerapp bash

Inspeccionar el archivo host, para comprobar la entrada de conexión con el redis
$ more /etc/hosts
$ ping redis

Inspeccionar la información de la IP en el contenedor:
docker inspect python-dockerapp | grep IP

Beneficios de Enlaces entre Contenedores Docker
- El uso principal de los enlaces entre contenedores docker es que cuando compilamos una aplicación con una arquitectura microservicio, seremos capaces de ejecutar muchos componentes independientes en contenedores diferentes
- Docker crea un túnel seguro entre los contenedores que no requieren exponer ningún puerto externamente del contenedor


Docker compose

- La vinculación manual de contenedores y servicios de configuración se convierten impráctivos cuando el número de contenedores crece.
- Docker compose es una herramienta de docker que permite definir y ejecutar aplicaciones multicontenedor.

$ docker-compose up  # Crea e inicia todos los contenedores
$ docker ps # verificar funcionamiento

- Docker compose es una herramienta útil para iniciar rápidamente el entorno de Docker.
- Docker compose usa archivos yml para almacenar la configuración de todos los contenedores, lo cual elimina la carga de mantener nuestros scripts para la organización de docker

Estudio detallado del flujo de trabajo de docker-compose

$ docker-compose up -d
$ docker-compose ps                 # Mostrar el estado de los contenedores administrados por docker-compose
$ docker-compose logs               # Opción para mostrar los logs de los contenedores administrados por el docker-compose, que se encuentran en el archivo, diferenciados por colores
$ docker-compose logs dockerapp     # Mostrar los logs de un contenedor específico
$ docker-compose stop               # Detener los contenedores sin eliminarlos
$ docker-compose up                 # Para iniciar los contenedores nuevamente, también se puede hacer mediante el comando docker-compose start
$ docker-compose rm                 # Eliminar los contenedores, pedirá confirmación para eliminarlos
$ docker-compose build              # Reconstruye las imágenes de docker del archivo docker-compose que se encuentre activo, esto se hace ya que por defecto docker-compose construye la imagen si la misma no ha sido generada, con este comando se forza a la generación de la imagen

Problemas potenciales que podrías enfrentar cuando trabajes con Contenedores Docker
https://www.level-up.one/things-watch-working-docker-containers/

Introducción a la Red de contenedores de docker

Modelo de red predeterminado de docker
- Docker utiliza las capacidades de red del sistema operativo del equipo host para proporcionar soporte de red a los contenedores que se ejecutan en ese equipo
- Una vez que el daemon de docker es instalado en el equipo host, una interfaz de red docker0, estará disponible en el equipo host, la cual será usada para enlazar el tráfico desde la red externa con la red interna de los contenedores alojados en el equipo host
- Cada contendor se conecta a la red puente a través de su interfaz de red los contenedores.
- Los contenedores pueden conectarse entre si y con la red exterior a través de esta interfaz puente, este es el modo en el que se comporta el modo predeterminado de red de docker

Closed Network / None Network
Bridge Network - Predeterminado
Host Network
Overlay Network

verificar las redes de docker
$ docker network ls



Tipo de red "Network None"
- Esta red no tiene acceso al mundo exterior
- La red none agrega un contenedor a un stack de red de contenedores específico
- El nuevo contenedor carece de una interfaz de red y estará totalmente aislado, a este tipo de contenedores se denominan un contenedor cerrado

Iniciar un contenedor dentro de la red none
$ docker run -d --net none busybox sleep 1000

Iniciar sesión dentro del contenedor
$ docker exec -it eager_hodgkin /bin/ash

Verificar conectividad haciendo un ping a la DNS pública de Google
$ ping 8.8.8.8

Validar las interfaces de red
$ ifconfig

En el contenedor de red perteneciente a una red none, no aparecerá ninguna interfaz de red, y solamente existirá una interfaz de redd loopback, no está conectada a ninguna red, y tiene asignada la IP 127.0.0.1, es solamente utilizado por las aplicaciones internas para comunicarse entre sí

- Provee el máximo nivel de protección de red. Ya que los contenedores no se pueden accederse desde una ubicación externa al equipo host que está ejecutando el contenedor dentro de docker
- Esta conexión no es una buena idea si la red o la conexión a internet es requerida
- Se adapta bien si el contenedor requiere el máximo nivel de seguridad de red, y cuando el acceso a una red de ordenadores o intenet no es necesario


Red Bridge

- Este es el tipo de red predeterminado en contenedores de red docker
- Todos los contenedores de una red bridge, están conectados entre sí y con el mundo exterior cuando están conectados a la interfaz bridge

verificar las redes de docker, para listar todas las interfaces de red docker en el host local
$ docker network ls

Apenas se inicialice el daemon de docker, se creará una interfaz predeterminada bridge llamada "bridge". Para verificar los detalles de la red bridge, ejecutando el comando docker network inspect:
$ docker network inspect bridge
- Rango predeterminado de la red bridge, es 172.17.0.0 a 172.17.255.255

$ docker run -d --name container_1 busybox sleep 1000

Comprobar las interfaces de red a través del comando siguiente:
$ docker exec -it container_1 ifconfig

La interfaz de red privada está contectada a la red bridge, y está dentro del intervalo de direcciones IP predeterminado

Ejecutar otro comando de red
$ docker run -d --name container_2 busybox sleep 1000

Los contenedores pueden usar esta interfaz de red privada para comunicarse entre sí
$ docker exec -it container_1 ping 172.17.0.3

Y con internet, haciendo un ping al DNS público de Google:
$ docker exec -it container_1 ping 8.8.8.8

Sin embargo, por defecto, las diferentes redes bridge están aisladas entre sí, los contenedores dentro de una red bridge no pueden acceder a los contenedores dentro de otra red bridge

Crear otra red brigde personalizada:

$ docker network create --driver bridge my_bridge_network

Verificar el rango de IP de la red:
docker network inspect my_bridge_network

Ejecutar el contenedor 2 desde la nueva red bridge:
$ docker run -d --name container_3 --net my_bridge_network busybox sleep 1000

Comprobar las interfaces de red a través del comando siguiente:
$ docker exec -it container_3 ifconfig

Para comprobar si la red bridge están aisladas unas de otras (las redes bridge extán en diferentes redes)
$ docker exec -it container_3 ping 172.17.0.2

Sin embargo docker tiene una función que nos permite conectar un contenedor docker a otra red, una vez conectado, el contenedor puede comunicarse a con los otros contenedores dentro de la misma red
$ docker network connect bridge container_3

Comprobar nuevamente las interfaces de red a través del comando siguiente:
$ docker exec -it container_3 ifconfig

Podemos comprobar que el contenedor tieneU una interfaz de red adicional cuya IP está dentro de rango de IPs de a red bridge
Esto se comprueba a través de un ping

$ docker exec -it container_3 ping 172.17.0.2

También podemos desconectar el contenedor 3
$ docker network disconnect bridge container_3


Redes Bridge
- En una red bridge, los contenedores tienen acceso a dos interfaces de red:
    - Una interfaz de red loopback, que no tiene acceso a la red exterior
    - Una interfaz privada que está conectada a la red bridge del host, siendo este último el que utiliza para conectarse a la red externa
- Todos los contenedores en la misma red bridge pueden comunicarse entre sí
- Por defecto, los contenedores entre diferentes redes bridge no pueden comunicarse entre sí
- Pero se pueden conectar manualmente uno o varios contenedores a otras redes bridge, y así lograr que se comuniquen
- El modo bridge es el modelo de red más común en docker
- Reduce el nivel de aislamiento de la red a favor de una mejor conectividad externa
- Más adecuada para configurar una red relativamente pequeña en un solo host



Redes host y overlay

- La red Host es el modo de red menos protegido, agrega un contenedo a el estack de redes del host
- Contenedores deslegados en el stack del host tiene acceso completo a la interfaz del host
- Este tipo de contenedores son usualmente conocidos como contenedores abiertos

$ docker run -d --name container_4 --net host busybox sleep 1000

Comprobar las interfaces de red del contenedor a través del comando siguiente:
$ docker exec -it container_4 ifconfig

El contenedor puede acceder a todo las interfaces de red configuradas en el host

Red Host
- Mínimo nivel de seguridad de red
- No es posible aislar en ese tipo de contenedores abiertos, por lo cual se deja el contenedor ampliamente desprotegido
- Contenedores en ejecución en el stack de redes del host deben tener un mayor nivel de rendimiento comparados con aquello ejecutándose en asignaciones de puerto docker0, bridge e iptables


Red Overlay
- Todos los modelos vistos hasta el momento, tienen la limitación de ejecutarse en una sola máquina host
- Por lo tanto el modo de red Overlay soporta múltiples máquinas host
- Requiere algunas condiciones preexistentes antes de que sean creadas
    - Ejecutar el docker engine en modo Swarm
    - Un servicio de almacenamiento clave valor válido
    - Es una red ampliamente usada en producción
    - Es una red utilizada en la implementación de varios host a través de Docker Swarm

https://docker-docker.com/engine/userguide/networking/overlay-standalone-swarm/#create-a-swarm-cluster


Definir modelos de Red a través de Docker Compose

Por defecto, docker compose configura un tipo de red predeterminada a la cual los contenedores se unirán, y también sera accesible a contenedores de esa red.

Para verificar que los contenedores al momento de crearse, se agregan en una red por defecto con driver bridge
$ docker network ls


Se pueden también definir topologías de red más complejas, en las que se pueden definir aislamiento de red entre servicios, estos tipos de aislamiento de red son muy populares entre aplicaciones de varios niveles:

version: '2'
services:
  proxy:
    build: ./proxy
    networks:
      - front
  app:
    build: ./app
    networks:
      - front
      - back
  db:
    image: postgres
    networks:
      - back
networks:
  front:
    driver: custom-driver-1
  back:
    driver: custom-driver-2
    driver_opts:
      foo: "1"
      bar: "2"


Escribir pruebas unitarias entre contenedores:
Pruebas unitarias para la aplicación, y cómo ejecutarlas dentro de un contenedor
- Las pruebas unitarias testean algunas funcionalidades básicas de nuestro código docker app, sin depender de servicios externos
- Las pruebas unitarias deberán ejecutarse tan rápido como sea posible para que los desarrolladores puedan iterar más rápido sin esperar demasiado por los resultados
- Los contenedores DOcker se pueden crear en segundos, facilitando la creación de un entorno limpio y aislado siendo una gran herramienta para ejecutar pruebas unitarias

Se utiliza un framework de pruebas unitarias llamado unitest

Se utiliza un comando especial de docker-compose, para ejecutar un comando que esté presente dentro de un servicio de un contenedor
$ docker-compose run dockerapp python test.py

Incorporando pruebas unitarias
Ventajas
- Una sola imagen se utilizará para desarrollo, entorno de pruebas y producción, lo cual garantiza la confabilidad de nuestras pruebas.
Desventajas
- Incrementa el tamaño de la imagen



Adaptar la tecnología de  Docker en el Proceso de Integración Continua (CI)

¿Qué es integración continua?

- la integración continua es una práctica de ingeniería de software en la que los cambios aislados se prueban y se informan inmediatamente cuando estos cambios son añadidos a un código base más grande
- El objetivo de la Integración Continua es proprocionar retroalimentación rápida de modo que si se introduce un defecto al código base, este será identificado y corregido tan pronto como sea posible

URL de la cuenta Github para hacer fork:

https://github.com/jleetutorial/dockerapp


Chequeo para keys SSH existentes:

https://help.github.com/articles/checking-for-existing-ssh-keys/


Genera una nueva key SSH y agrégala al agente ssh:

https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/


Agrega una nueva key SSH a tu cuenta GitHub:
https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/


Introducción a Ejecución de Docker en producción

Opiniones acerca de Ejecutar Docker en producción
- Por un lado, muchos usuarios de Docker confían en que una app web distribuida se puede implementar a escala utilizando Docker, por lo que han incorporado docker en producción.
- Por otro lado, hay algunos usuarios que dudan en usar docker en producción ya que piensan que el flujo de trabajo de docker es muy complicado o inestable al tratar de aplicarlo en proyectos

¿Docker está listo para usarse en producción?

Preocupaciones acerca de Ejecutar Docker en producción
- Se necesitan aclarar como Docker aborda temas tales como la persistencia de datos, redes, seguridad y gestión de identidad
- El ecosistema de soporte de aplicaciones dockerizadas en producción tales como herramientas de monitoreo y registro todavía no están listas

Compañías que están usando Docker usando Docker en Producción:
- Spotify
- yelp

¿Por qué ejecutar contenedores docker dentro de máquinas virtuales?
- Para considerar problemas de seguridad
- Aislamiento a nivel de hardware

Todos ellos ejecutan contenedores dentro de máquinas virtuales:
- Google Contain Engine
- Amazon S2 container services

Docker Machine
- Configurar nuevas máquinas virtuales
- Instalar máquinas docker en ellas
- Vincular el cliente docker con las máquinas docker remotas

Controladores de Docker Machine
- AWS
- DigitalOcean
- VirtualBox
- Google App Engine


Registra tu cuenta en DigitalOcean para Desplegar Aplicaciones en Contenedores


Crear cuenta en Digital Ocean
- Crear una cuenta en Digital Ocean, o autenticarse con la cuenta de GitHub
- Inscribir tarjeta de crédito
- Canjear un cupón de pago gratuito, para utilizar la máquina virtual más básica para montar los contenedores en la nube pública

Instalar Docker-machine, en windows o en Mac
Docker Machine proporciona drivers para conexión a los servicios de nube más populares como Amazon AWS, y Microsoft Azure, en este caso se va a utilizar el proveedor de Digital Ocean

Comando para especificar el token de conexión a la cuenta de Digital Ocean
$ docker-machine create --driver digitalocean --digital-access-token

Comando para aprovisionar la máquina virtual de DigitalOcean, especificando la máquina virtual con el docker engine preinstalado, como también los certificados
$ docker-app-machine

Mostrar los comandos necesarios para configurar el entorno del cliente docker, para que se pueda conectar a la máquina virtual que se acabó de aprovisionar
$ docker-machine env docker-app-machine

Se modifica el archivo docker-compose.yml, y se renombra como prod.yml, en el cual se modifica la instrucción build, por la instrucción de image, esto es para traer la imagen que se encuentra en dockerhub y que fue construida a través de CircleCI

Una ve modificado se ejecuta el siguiente comando:
$ docker-compose -f prod-yml up -d

Esto desplegará todos los archivos definidos en el archivo de docker-compose

Mostrar todas las máquinas virtuales:
$ docker-machine ls


Comando Docker Machine Create
$ docker-machine create --driver digitalocean --digitalocean-access-token <XXXX> docker-app-machine

Introducción a Docker Swarm y Configurar un Clúster Swarm

Qué sucedería si existe un sistema complicado de muchos contenedores, y que los mismos no puedan soportarse en un solo servidor?

- Docker Swarm es una herramienta que agrupa muchos Docker engine y programa contenedores
- Docker Swarm decide qué host ejecuta el contenedor en función de los métodos de planificación

Por un lado se tiene los docker host cada uno con los docker deamon que se ejecutan en cada uno de los host. También se configura docker swarm, que es el administrador de clústeres de docker, entre el cliente docker y los hots. El administrador Swarm estárá conectado todos y cada uno de los docker daemon, con lo cual tendrá el estado de los docker deamon de cada uno de los nodos del clúster. Cuando se va a ejecutar un servicio, el administrador Swarm decidirá donde ejecutar el servicio, solamente se tiene que direccionar el cliente docker al administrador Swarm, en lugar de hacerlo en todos y cada uno de los docker deamons. Básicamente Docker Swarm puede agrupar varios host en un clúster, y distribuir contenedores docker en estos host. Por lo que las cargas de trabajo se repartirán en los nodos dentro del Swarm, y esto es sabido por los usuarios finales. De esta manera, Docker Swarm se encarga de las tareas de planificación manual, desde el cliente al administrador Swarm. También es posible direccionar varios clientes docker al mismo administrador Swarm, de modo de varios usuarios puedan compartir el mismo clúster Swarm. Existen tres conceptos importantes en Docker Swarm:

- Nodo: Una instancia del docker engine que participa en el Swarm, se puede ejecutar uno o más nodos en una sola computadora o en un servidor en la nube. La producción de despliegues a Swarm suele incluir nodos docker distribuídos en múltiples máquinas distribuídas y en la nube
- Nodo Administrador:
- Nodo de trabajo:


Cómo trabaja un Clúster Swarm

- Para desplegar nuestra aplicación a Swarm, se debe enviar el servicio a un nodo administrador
- El nodo administrador despacha unidades de trabajo llamadas tareas a los nodos de trabajo
- Los nodos administradores también realizan las funciones de orquestación y gestión de clústeres necesarias para mantener el estado deseados del swarm. Los nodos administradores eligen una única unidad para llevar a cabo tareas de orquestación
- Los nodos de trabajo reciben y ejecutan tareas enviadas desde los nodos administradores. Por defecto, los nodos administradores también ejecutan servicios como nodos de trabajo, pero se pueden configurar para ejecutar exclusivamente tareas de administrador y funcionar únicamente como nodos administradores.
- Un agente se ejecuta en cada nodo de trabajo e informa de las tareas asignadas a este. El nodo de trabajo notifica al nodo administrador del estado actual de las tareas asignadas de modo que el administrador mantendrá el estado deseado de cada nodo de trabajo

Configurar un clúster swarm

- Paso 1: Crea dos máquinas virtuales, una será usada para el nodo administrador de swarm, y el otro será usado para el nodo de trabajo
- Paso 2: Nombra la primer máquina virtual como un administrador de Swarm e iniica un clúster swarm
    - docker swarm init
- Paso 3: Deja que la segunda máquina virtual se una al clúster swarm como un nodo de trabajo
    - docker swarm join
        Inicializa el swarm. El docker engine modificado por este comando se convertirá en un nodo administrador en el swarm de un solo nodo recientemente creado.
    - docker swarm join --token SWMTKN-1-3atc7surkl3wsvy0r07zt1xar1m1ecja46lwcsajjflxkgplk4-1bh5ukwpx30mhdc7mxo2tyaxz 192.168.1.9:2377
        Agrega la seguna máquina virtual al clúster swarm como si fuera un nodo de trabajo
    - docker swarm leave
        Desconecta el nodo del cluster swarm


Servicios en Docker
- Los servicios pueden ser definidos en nuestro archivo Docker compose
- La definición del servicio incluye qué imagenes de Docker se ejecutarán, la asignación de puerto y la dependencia entre servicios
- Cuando se despliegan servicios en modo swarm, también existe otra configuración muy importante que se refiere a la llave deploy y solo está disponible en formatos de archivos Docker compose versión 3.0 y posteriores

version "3.0"
services:
    dockerapp:
        image: jleetutorial/dockerapp
    ports:
        - "5000:5000"
    depends_on:
        - redis
    deploy:                 # La llave deploy, y sus subopciones se pueden usa para equilibrar la carga y optimizar el rendimiento de cada servicio
        replicas: 2
    redis:
        image: redis:3.2.0

Observar el siguiente archivo docker-compose.yml


version: "3.3"
services:
    nginx:
        image: nginx:latest
    ports:
        - "80:80"
    deploy:
        replicas: 3         # docker ejecutará 3 instancias de la imagen nginx
        resources:
            limits:
                cpus: '0.1'
                memory: 50M
        restart_policy:
            condition: on_failure

Qué es una réplica?

Cuando se despliega el servicio nginx a swarm, el administrador swarm acepta la definición del servicio como el etsado deseado del servicio, luego swarm planifica la ejecución del servicio nginx en 3 nodos que pertenecen al clúster swarm, cada nodo ejecutará un contenedor nginx, y estos se llaman réplicas. Por qué se busca ejecutar los contenedores en varios host?
Esto se hace para lograr escalabilidad y alta disponitiblidad. Lo que significa que la aplicación podrá escalar si el número de usuarios se incrementa, y la aplicación permanecerá en línea si uno de los contenedores falla.


Es posible preguntarse si es posible acceder a cualquier contenedor nginx desde cualquiera de los 3 host? la respuesta es que si es posible, en el archivo de docker-compose.yml, se le está indicando a docker que publique el puerto 80 como un puerto disponible para el servicio nginx. Cuando docker publica un puerto para un servicio, lo hace asignando ese puerto a todos los nodos dentro del clúster swarm, cuando el tráfico llega a ese puerto, ese tráfico se enruta a un contenedor ejecutándose en ese servicio, por lo que es posible acceder s nginx visitando el puerto 80 en cualquiera de los tres host. Este concepto es bastante estándar cuando todos los nodos están ejecutando un contenedor de servicio. Sin embargo es bastante interesante cuando se tienen más nodos que réplicas.

Por ejemplo se tienen 4 nodos en el clúster swarm, y swarm desplegó únicamente 3 réplicas del servicio nginx. Qué pasaría si llega una petición al nodo swarm que no tiene una rélica en ejecución del contenedor de nginx? La respuesta es que aún sería posible de conectar al servicio nginx a través de un nodo que no tiene una réplica del servicio nginx.
Esto se denomina en docker como equilibrio de ingreso de carga
    - Todos los nodos de trabajo estarán pendientes para conectar puertos de servicio
    - Cuando el servicio es llamado por sistemnas externos, el nodo receptor aceptará ese tráfico, e internamente equilibrará la carga utilizando un servicio interno de DNS que el servicio de Docker mantiene
Por lo que es posible que si se escala a 100 nodos de trabajo, los usuarios finales de nuestro servicio nginx podrán conectarse sin problemas a cualquier nodo de trabajo, luego serán redirigidos a cualquiera de los host que estén ejecutando el contenedor, y luego van a ser redirigidos a cualquiera de los host que estén ejecutando los contenedores. Todo el redireccionamiento y balanceo de carga es transparente al usuario final.

Además de las réplicas, es posible configurar aspectos como  por ejemplo limitar a las réplicas a usar como máximo el 10% de la CPU en todos los microprocesadores, y 50MB de ram. es posible incluso solicitar a docker que reinicie los contenedores inmediatamente en caso uno de ellos falle, en garantizar que el servicio se encuentre siempre en línea. Mediante todo este proceso docker tiene como objetivo principal proporcionar escalabilidad de compilación, y un soporte de alta disponibilidad para el servicio desplegado en un clúster docker swarm

Antes de poder desplegar el servicio en docker swarm, existe otro concepto en swarm: Docker Stack

Docker Stack
Este es un concepto reciente de Docker.
- Un docker stack es un grupo de servicios interrelacionados que comparten dependencias, y se pueden organizar y escalar juntos
- Se puede imaginar un stack como una colección activa de todos los servicios definidos en el archivo de Docker Compose:
    - docker stack deploy
- En el modo Swarm:
    - Se pueden reutilizar todos los comandos de Docker Compose para la definición de los servicios.
    - Los comandos Docker Compose no pueden ser reutilzados. Los comandos docker compose solo se pueden programar en contenedores de un solo nodo.
        docker-compose up
        docker- compose down
- En el modo swarm, se tendrá que utilizar docker stack
- Se puede pensar en docker stack, como un docker compose para el docker swarm

Inicializar el docker stack en el clúster swarm:
 $ docker stack deploy --compose-file prod.yml dockerapp_stack

Comprobar el estado del stack:
 $ docker stack ps dockerapp_stack

Mostrar los nodos de docker en modo swarm:
 $ docker node list

Al momento de crear el stack, docker automáticamente crea una red overlay llamada dockerapp_stack_default para comunicación cruzada de nodos. Por lo general no es necesario personalizar la configuración de la red en docker stack. Entonces docker creará los servicios dockerapp y redis. También se puede enumerar todos los stack en el cluster swarm, con el comando

Listar los stacks que se encuentran instanciados en el docker swarm
$ docker stack ls

Listar los servicios en docker stack
$ docker stack services dockerapp_stack


Que hay de nuevo en Docker 17.06

Docker 17.06

Docker 17.06 (stable) fue lanzado en Junio del 2017!  Docker avanza muy rapido, con un canal de borde lanzado cada mes y una lanzamiento estable cada 3 meses

Mira un video de Mango dando un resumen de las nuevas características en la comunidad de edición Docker 17.06.

Para una lista detallada de cambios, mira a través de las notas lanzadas por Docker CE en GitHub.


Soporte Nativo de Docker para Kubernetes

En el DockerCon 2017, llevado a cabo en Copenhague, Docker anunció que estará agregando soporte para ejecutar aplicaciones usando el orquestador de Docker Swarm con Kubernetes en el mismo clúster de computadoras.

Kubernetes es una plataforma de orquestación de contenedores que no cubrimos mucho en este curso (¡Pronto tendremos un curso sobre Kubernetes!). Kubernetes es una alternativa a Docker Swarm, pero a comparación de Docker Swarm, Kubernetes está más preparado para producción.

¡Ésta es una gran noticia! ¡La introducción del soporte nativo de Docker para Kubernetes nos da la posibilidad de elegir una orquestación con características propias de Docker tales como: seguridad adicional, administración y la experiencia de principio a fin de Docker, que hemos esperado durante tanto tiempo!



Texto de soporte: Aprendizaje Futuro

    Obtén una copia GRATIS de nuestro Libro DevOps

https://www.level-up.one/devops-pdf-book/

    Únete a nuestro grupo de Facebook para DevOps

https://www.facebook.com/groups/1911219079195863/


Clase Extra: Cupones para Otros de Nuestros Cursos

Nos complace ofrecérles un cupón de descuento de $15 a nuestros estudiantes para todos nuestros cursos en Udemy.

Domina Jenkins CI para DevOps y Desarrolladores ($15,  Udemy Best Seller en Categoria Jenkins)
https://www.udemy.com/domina-jenkins-ci-para-devops-y-desarrolladores/?couponCode=EXISTING_STUDENT

IntelliJ IDEA Tricks to Boost Productivity for Java Devs ($15)
https://www.udemy.com/intellij-idea-secrets-double-your-coding-speed-in-2-hours/?couponCode=DOCKER_STUDENT_15

Apache Spark with Java - Mastering Big Data! ($15, Udemy Best Seller in Apache Spark Category)
https://www.udemy.com/apache-spark-course-with-java/?couponCode=DOCKER_STUDENT_15


