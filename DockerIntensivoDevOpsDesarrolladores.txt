

Docker Intensivo para DevOps y Desarrolladores

- Introducción a las tecnologías de virtualización
- Arquitectura Cliente-Servidor de Docker
- Instalación de Docker en nuestra máquina
- Conceptos importantes de Docker
- Correr nuestro primer container Hello World! en Docker
- Comandos más útiles para trabajar con Docker
- Capas de imagen
- Docker commit - crear imagenes
- Docker file
- Instrucciones del dockerfile
- Push de imagenes

- Dockerizar una aplicación sencilla
- Servicio de búsqueda con redis
- Enlazar contenedores
- Vinculación de contenedores de manera interna
- Automatizar el flujo de trabajo con docker-compose

- Pruebas unitarias para probar la aplicación dockerizada
- Flujo de trabajo con docker, github y CircleCI para crear una pipeline de integración continua

- Ejecutar docker en producción
- Desplegar nuestra aplicación dockerizada servidor de producción con Digital Ocean
- Docker swarm, para escalar los flujos de trabajo


Código fuente utilizad en GitHub
- https://github.com/jleetutorial/dockerapp

Grupo de Facebook de Learning DevOps
https://www.facebook.com/groups/1911219079195863


Vitualización basada en contenedores
- Previrtualización
    Grandes racks de servidores, cada servidor un sistema operativo y solamente pueden ejecutar un servicio
    Alto costo ya que se deben adquirir servidores
    Subutilizando recursos de RAM y CPU
    Despliegue lento, proceso de compra y configuración puede tomar mucho tiempo para grandes empresas
    Difíciles de migrar aplicaciones

Virtualización basada en Hypervisor
- Servidor físico
- Sistema Operativo
- Hypervisor
- Instalación de varios sistemas operativos
- Instalación de varias aplicaciones sobre los sistemas operativos
- VMWare y VirtualBox
- AWS - Microsoft Azure

Ventajas
- Más Rentable
- Propios recursos
- Pago por potencia de computo y almacenamiento
- Facil de escalar
- Reducción del tiempo de semanas en minutos

Limitaciones
- Duplicación del recurso del kernel, varios sistemas operativos para atender el servicio de aplicaciones
- Problemas con la portabilidad de la aplicación

Virtualización basada en contenedores

- Servidor físico -máquina física o máquina virtualización
- Sistema operativo
- Motor de contenedores
- Instancia de invitado o contenedor
- Aplicación con sus respectivas librerías
- Replicación de kernels, comparten un único kernel, suministra binarios y tiempos de ejecución
- Virtualización a nivel del sistema operativo

Aislamiento
- Cómo ejecutar aplicaciones en distintos entornos de ejecución de Java, aislados por contenedores
- Aislamiento de tiempo de ejecución

Beneficios
- Más rentable, no crea un SO completo, solamente los componentes necesarios se empaquetan en el contenedor con la aplicación
- Menor consumo de RAM y CPU
- Velocidad de implementación aún más rápida
- Gran portabilidad, ya que cuentan con todo lo necesario para su ejecución dentro del contenedor, se puede ejcutar en todas la máquinas sin problemas de portabilidad


Arquitectura cliente-servidor de docker
- Docker utiliza la arquitectura cliente-sevidor, con el daemon de docker como servidor, el usuario no interactúa directamente con el daemon de docker, sino a través del cliente docker. El cliente de docker es la interfaz principal de comunicación entre el usuario y el servidor
- Cliente con línea de comandos - Kitematic, cliente gráfico
- Daemon es un proceso persistente que hace el trabajo pesado como construir, ejecutar y distribuir los contenedores docker, a menudo conocidos como docker dameon, docker engine, ó docker server
- En una instalación típica de linux, el cliente docker, el daemon docker y el contenedor se ejecutan en el mismo host, también se puede conectar el cliente local de docker, con un servidor remoto de docker.
- No se puede ejecutar docker de forma nativa en mac, Windows, y en general en platformas que no sean Linux, porque este utiliza funciones específicas del kernel de Linux

Instalación de docker en varios sistemas operativos

$ docker info   # mostrará la información de todo el sistema sobre docker


Instalar docker toolbox

Conceptos importantes que hay que entender acerca de la tecnología de docker
- Las imágenes son plantillas de lectura utilizadas para crear contenedores
- Las imágenes se crean mediante el comando build de docker, por nosotros y otros usuarios de docker
- Las imágenes son compuestas de capas de otras imágenes
- Las imágenes solo se almacenan en un registro de docker

Contenedores
- Haciendo una analogía con la POO, si una imagen es una clase, entonces un contenedor es una instancia de una clase, un objeto de tiempo de ejecución
- Los contenedores son livianos y portátiles de un entorno en el cual se pueden ejecutar aplicaciones
- Los contenedores son creados de imágenes. Dentro de un contenedor, tenemos todos los binarios y dependencias que necesitamos para ejecutar la aplicación

Registros y repositorios
- Un registro es donde están almacenadas nuestras imágenes
- Puedes alojar tu propio registro, o puedes usar el registro público de Docker el cual es llamado DockerHub
- Dentro de un registro, las imágenes se almacenan en repositorios
- El repositorio de Docker es una colección de diferentes imágenes de docker con el mismo nombre, que tienen etiquetas, cada etiqueta generalmente representa una versión diferente de la imagen

Por qué se utilizan imágenes oficiales?
- Documentación clara
- Docker.inc, tiene un equipo dedicado a la revisión del contenido de las imágenes
- Actualizaciones de seguridad de manera oportuna
- Repositorios certificados por docker

$ docker images                                 # comando para mostrar las imágenes en el registro local de docker
$ docker run busybox:1.24 echo "hello world"    # crea un contenedor a partir de una imagen
$ docker run --rm --name helloworld -d busybox:1.24     # crea un contenedor, que cuando termine la ejecución, se borra, que se llama helloworld, y basado en la imagen busybox:1.24
$ docker run -ti busybox:1.4                    # crea un nuevo contenedor con ingreso a terminal dentro del contenedor


$ docker run -d busybox:1.24 sleep 1000         # crea un contenedor en segundo plano o en background con el modificador -d. Contenedores empezaron en modo detached y salen cuando el proceso raíz usado para ejecutar el contenedor sale

$ docker ps                                     # listar los contenedores que se encuentran actualmente en ejecución
$ docker ps -acerca                             # listar todos los contenedores, incluso los que ya no están en ejecución
$ docker run --rm busybox:1.24 sleep 1          # crea un contenedor con el comando sleep de un segundo, para que se mantenga en ejecución por un segundo, y a continuación cuando se detiene, se elimina ya que se le envió el modificador --rm
$ docker run --name hello_world busybox:1.24    # especifica el nombre hello_world, mediante el modificador --name
$ docker inspect                                # mostrar la información de bajo nivel sobre un contenedor o imagen


Continuación comandos docker
Docker port mapping
Docker logs

$ docker run -it --rm -p 8080:8080 tomcat:latest
$ docker logs {id_contenedor}

Para aprender más sobre el uso de Docker Logging, entra al siguiente enlace:

https://www.level-up.one/deep-dive-into-docker-logging/

Capas de imágenes en docker

Una imagen de docker se compone de una lista de capas de solo lectura, que representan un conjunto de cambios en el sistema de archivos del contenedor, las capas de imágenes se agrupan una encima de otra y crean una última capa en modo escritura para los contenedores. Cada imagen consiste de múltiples capas, y cada capa es solo otra imagen, las imágenes padres son de solo lectura, y encuentra debajo de la capa editable. La imagen que se encuentra en la parte interior, se denomina imagen base. Docker realiza todos los cambios en la capa editable. También se puede saber qué conjunto de imágenes conforman una imagen, ejecutando el comando history de docker:

$ docker history busybox:1.24

Cuando se crea un nuevo contenedor, se crea una nueva capa delgada y en modo escritura encima de la pila existente. A esa capa a menudo se le denomina capa de contenedor editable. Todos los cambios realizados en el contenedor en ejecución, como la escritura de archivos nuevos, la modificación de archivos existentes, y la eliminación de archivos, se escribe en esta capa.
La principal diferencia entre un contenedor y una imagen, es la capa superior en modo escritura. Todos los cambios en el contenedor, que agregan datos nuevos o  modifican los existentes, se almacenan en esta capa. Cuando se elimina el contenedor, esta capa también se elimina, la imagen subyacente permanece sin cambios ya que cada contenedor tiene su propia capa editable, y todos los cambios se almacenan en ésta. Esto significa que múltiples contenedores, pueden contener el acceso a la misma imagen subyabcente, y tener su propio estado de datos.

1. Todos los cambios realizados en el contenedor en ejecución serán escritos en la capa editable.
2. Cuando el contenedor es eliminado, la capa editable es también eliminada, pero la imagen subyacente permanece sin cambios.
3. Múltiples contenedores pueden compartir acceso a la misma imagen subyacente.


Construir imágenes docker

1. Hacer commit de los cambios realizados en un contenedor
2. Escribir un Dockerfile

Pasos
1. Lanzar un contenedor desde una imagen base
2. Instala el paquete git en el contenedor
3. Usar docker commit para guardar los cambios realizados en un contenedor

Se crea un nuevo contenedor a partir de la imagen de dockerhub de debian:jessie
$ docker run -it debian:jessie

Si se requiere una nueva versión de la imagen con el cliente git instalado, se abre una terminal del contenedor, y a continuación se instala con las siguientes instrucciones:
$ apt-get update && apt-get install -y git

Ahora para guardar la capa de contenedor de docker como una nueva imagen, se utiliza el comando docker commit:

DOcker commit
- El comando docker commit guardará los cambios que hemos realizado en el sistema de archivos del contenedor docker a una nueva imagen

$ docker commit container_id repository_name:tag

Al realizar commit, se guarda en el reposotorio local de docker
$ docker commit b54675f35b9b danrojas7/debian:1.0

Ahora se puede crear un nuevo contenedor basado en la nueva imagen de docker que se acabó de construir:

docker run -it danrojas7/debian:1.0

para subir la imagen, se utiliza el siguiente comando:

$ docker login                          # se ingresa el usuario y la contraseña por el prompt
$ docker push danrojas7/debian:1.0


Construcción de imágenes docker mediante archivos docker o dockerfiles

Un Dockerfile es un documento de texto que contiene todas las instrucciones que los usuarios proporcionan para construir una imagen

Una instruccion puede ser la instalación un nuevo programa, agregar un código fuente o especificar un comando que se ejecutará posteriormente de inicializado el contenedor

Docker puede construir imágenes automáticamente leyendo las instrucciones desde un Dockerfile
- Cada instrucción creará una nueva capa de imagen para la imagen
- Las instrucciones especifican qué hacer al construir la imagen

Un Dockerfile no debe tener ninguna extensión, para crearlo, se utiliza los siguientes comandos:

$ touch Dockerfile
$ vim Dockerfile

FROM debian:jessie      # FROM: Para indicar la imagen desde donde se está construyendo
RUN apt-get update && apt-get install -y git        # RUN: Se utiliza para indicar los comandos que se van a ejecutar, desde una terminal de comandos linux
RUN apt-get install -y vim

A continuación, para construir la imagen con el Dockerfile recién creado, se ejecuta el siguiente comando:

$ docker build -t danrojas/debian .

De igual manera, el comando docker build, requiere una ruta, que es una ruta a el contexto de compilación de docker

Contexto de compilación de Docker
- El comando docker build toma la ruta al contexto de compilación como un argumento. La ruta especifica donde encontrar los archivos para el contexto de la compilación en el docker daemon. Por ejemplo si quisiéramos copiar un código fuente del disco local al contenedor, estos archivos deberían encontrarse en la ruta del contexto de compilación. Es de recordar que el docker daemon puede ejecutarse en una máquina remota, y que el Dockerfile no se analizará del lado del cliente. En el proceso de compilación el cliente docker primer empaquetará todos los archivos del contexto de compilación en un tarball, luego transfiere el archivo tarball al Docker Daemon.
- Por defecto, docker buscará el archivo Dockerfile en la ruta del contexto de compilación. Si el Dockerfile no se encuentra en la ruta del contexto de compilación, se puede indicarle a Docker que busque el archivo en la ruta del archivo proporcionado por la opción -f

Cuando se inicia el proceso de compilación de la imagen, el proceso de compilación comprende:
- En pimer lugar muestra el contexto de compilación enviado al docker daemon. El cliente de docker está transfiriendo todos los archivos dentro del contexto de compilación que es el directorio actual desde la máquina local al docker daemon.
- Docker sigue las instrucciones del Dockerfile, en el paso 2 ejecuta el paso de instalación de los paquetes con el apt-get, se puede ver la id del contenedor, lo que ocurre es que docker inicia un nuevo contenedor, de la imagen base de debian, y a continuación realiza la instalación a partir de los comandos apt-get especificados, estos contenedores se eliminan automáticamente
- El docker daemon ejecuta cada instrucción dentro de cada contenedor, un contenedor es un proceso editable que escribirá los cambios en el sistema de archivos en una imagen, en el caso particular se instalará un programa. Una vez que docker escrito los cambios en la imagen y la ha guardado, docker eliminará el contenedor. Entonces para cada instrucción, docker creará un nuevo contenedor, ejecuta las instrucciones, agregará una nueva capa a la imágen, y eliminará el contenedor. Básicamente los contenedores son temporales, simplemente se utilizan los contenedores para escribir capas de imágenes, y una vez que se terminan son eliminados. Las imágenes son persistentes y de sólo lectura.
- Una vez que los pasos se hayan completado, los pasos de la compilación se han ejecutado satisfactoriamente.
- Cuando no se especifica una etiqueta, la imagen queda con la etiqueta latest

Dockerfile en detalle
- Cada comando RUN ejecutará el comando en la capa superior editable del contenedor, y luego guardará el contenedor como una nueva imagen.
- La nueva imagen es usada en el siguiente paso en el Dockerfile. Entonces cada instrucción RUN creará una nueva capa de imagen.
- Es recomendado enlazar las instrucciones RUN en el Dockerfile para reducir el número de capas de imágenes que son creadas.


Dockerfile modificado:

FROM debian:jessie
RUN apt-get update && \
    apt-get install -y \
    git \
    vim # Se escribe en un solo comando la actualización y la instalación de paquetes para que se procesen en una sola imagen, resultando en una sola capa en lugar de 3
CMD ["echo", "hello world"]

Ordenar los Argumentos de varias líneas en forma Alfanumérica
- Esto ayudará a evitar la duplicidad de paquetes, esto ayudará a evitar la duplicación de paquetes, y facilitará la actualización de la lista


Instrucción CMD
- La instrucción CMD especifica qué comando quiere ejecutar cuando el contenedor se inicia
- Si no se especifica la instrucción CMD en el Dockerfile, docker usará el comando por defecto definido en la imagen base
- En el caso particular de la imagen debian jessie, el comando predeterminado es bash
- La instrucción CMD no se ejecuta cuando se construye la imagen, solamente se ejecutará cuando el contenedor se inicie
- Es posible ejecutar el comando en cualquiera de los formatos exec que se prefiera o en forma de shell

$ docker run --rm danrojas7/debian:2.0

También se puede sobreescribir el comando enviado como segundo argumento el comando a ejecutar
$ docker run --rm danrojas7/debian:2.0 echo "Hello docker"


Docker cache
- La compilación de los comandos en docker es más rápida que la primera vez, y esto es debido al docker caché
- Cada vez que Docke ejecuta una instrucción crea una nueva capa de imagen
- La siguiente vez, si la instrucciónno cambia, Docker simplemente reutilizará la capa existente

Sin embargo, si docker caché se utiliza demasiado, esto puede ocasionar problemas.
- Por ejemplo se tiene el siguiente Dockerfile:
FROM ubuntu:14.04
RUN apt-get update
RUN apt-get install -y git curl # Se especificará adicional el curl para instalará
- Docker detecta que las 2 primeras instrucciones no variarán, por lo tanto utilizará para ellas el docker caché
- Debido a que la actualización no se ejecuta, es posible que se obtenga una versión desactualizada de los paquetes

La solución es enlazar los comandos apt-get update e install, de modo, que siempre que se actualice la instrucción install, siempre traerá la última versión de los paquetes

FROM ubuntu:14.04
RUN apt-get update && \
    apt-get install -y \
    git \
    curl

También es posible indicarle a docker, que invalide la caché, utlizando el indicador de --no-cache=true

$ docker build --no-cache=true -t danrojas7/debian .

Instrucción COPY
La instrucción COPY copia nuevos archivos o directorios del contexto de compilación y los agrega al sistema de archivos del contenedor

instrucción ADD
La diferencia con COPY, es que ADD permite además descargar un archivo de internet y copiarlo en el contenedor
La instrucción ADD también tiene la capacidad de descomprimir automáticamente los archivos comprimidos
La regla es: usar COPY a menos que se esté seguro que no se necesite ADD


Llevando las imagenes al dockerhub
Llevar la imágenes docker al repositorio público de dockerhub, para que otros desarrolladores las puedan utilizar. De las imágenes construidas de forma manual con un commit, o con un Dockerhub
crear una cuenta en Docker Hub https://hub.docker.com

Muestra las imágenes de docker instaladas en el daemon de docker local
$ docker images

Espeficar etiqueta y tag a una imagen docker
$ docker tag id_contenedor danrojas7/debian:2.0

$ docker login
$ docker login --username=danrojas7
Ingresar usuario y contraseña

Hacer push a la imagen
$ docker push cuenta_docker_hub/imagen:tag
$ docker push danrojas7/debian:2.0

Última etiqueta
- Docker usará la etiqueta predeterminada latest cuando no se proporcione ninguna etiqueta
- Muchos repositorios usan esto para etiquetar la imagen estable más actualizada, sin embargo esto es aún solo una convención y no es algo obligatorio
- Las imágenes que son etiquetadas como latest no serán actualizadas automáticamente cuando se envíe una nueva versión de la imagen al repositorio
- Ignorar la etiqueta latest



Práctica de Docker

Descargar el proyecto de python desde el repositorio de github:
https://github.com/jleetutorial/dockerapp.git

Ejecutar el siguiente comando para iniciar sobre la versión del proyecto a trabajar
$ git checkout branch-v0.1

Dockerfile:

FROM python:3.5
RUN pip install Flask==0.11.1 redis==2.10.5
RUN useradd -ms /bin/bash admin                 # Crea un usuario, con la shell definida por defecto
USER admin                                      # Cambia al usuario creado anteriormente
COPY app /app                                   # Copia el directorio dentro del contenedor
WORKDIR /app                                    # Cambia al directorio de trabajo
CMD ["python", "app.py"]                        # Inicia la aplicación


Hacer build de la imagen:
$ docker build -t jleetutorial/dockerapp:0.1 .

Inicializar un contenedor docker, con la aplicación a partir de la imagen recién construída
$ docker run -d -p 5000:5000 --name python-dockerapp jleetutorial/dockerapp:0.1

Comando en linux y en Mac, para obtener detalles de la máquina virtual, como la dirección IP sobre la cual está en ejecución
$ docker-machine ls

Comando para inciar sesión dentro del contenedor:
$ docker exec -it python-dockerapp bash

Dentro del contenedor, ejecutar el comando siguiente, para comprobar el proceso python con la aplicación en ejecución, y que el contenedor esté en ejecución por el usuario creado en el Dockerfile, y no por el usuario root
$ ps aux


Comando en git para guardar los cambios provisionales, reestableciendo el estado de la rama al estado original, dando la posibilidad de cambiar de rama

$ git stash
.. Se realizan cambios en otras ramas, y se vuelve a la rama original
$ git stash list    # muestra los stash guardados
$ git stash apply   # Se regresa al punto de modificación del repositorio antes de ejecutar git stash

Uso de redis
- Redis es una estructura de datos de memoria integrada, usando como base de datos, caché y message broker
- Replicación incorporada y diferentes niveles de persistencia en disco
- Ampliamente usado en muchos productos críticos en el campo tales como Servicio Timeline de Twitter y Noticias de Facebook


Ejecutar la imagen de redis en un contenedor:
$ docker run -d --name redis redis:3.2.0

Hacer build de la imagen, e iniciar una nueva versión del contenedor:
$ docker build -t jleetutorial/dockerapp:0.3 .
$ docker run -d -p 5000:5000 --name python-dockerapp --link redis jleetutorial/dockerapp:0.3

Iniciar sesión en el contenedor
docker exec -it python-dockerapp bash

Inspeccionar el archivo host, para comprobar la entrada de conexión con el redis
$ more /etc/hosts
$ ping redis

Inspeccionar la información de la IP en el contenedor:
docker inspect python-dockerapp | grep IP

Beneficios de Enlaces entre Contenedores Docker
- El uso principal de los enlaces entre contenedores docker es que cuando compilamos una aplicación con una arquitectura microservicio, seremos capaces de ejecutar muchos componentes independientes en contenedores diferentes
- Docker crea un túnel seguro entre los contenedores que no requieren exponer ningún puerto externamente del contenedor


Docker compose

